---
title: "Wordle Probability Exercise"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

## Introduction

This exercise explores probability concepts using a simplified version of Wordle. In Wordle, players have six attempts to guess a five-letter word, receiving feedback after each guess:

- Green: Letter is correct and in the correct position
- Yellow: Letter is in the word but in the wrong position
- Gray: Letter is not in the word

While the official Wordle game has 2,309 possible target words, our simplified version uses just 200 common five-letter English words. This makes the probability calculations more intuitive while preserving the core concepts.

## Setting Up Our Word Database

First, let's create our database of 200 diverse five-letter English words from across the alphabet.

```{r}
# Set up the environment
set.seed(123) # For reproducibility

# Create a diverse list of 200 five-letter English words spread across the alphabet
common_words <- c(
  # A words
  "about", "adopt", "alert", "apple", "audio",
  # B words
  "beach", "bread", "blink", "burst", "basic",
  # C words
  "candy", "comet", "crash", "crust", "climb",
  # D words
  "doubt", "dough", "dance", "dream", "drape",
  # E words
  "earth", "early", "equal", "enjoy", "event",
  # F words
  "fight", "float", "flute", "fresh", "frame",
  # G words
  "glass", "grade", "greet", "guard", "guest",
  # H words
  "heart", "heavy", "happy", "horse", "house",
  # I words
  "index", "input", "image", "issue", "ivory",
  # J words
  "joint", "jumbo", "japan", "jolly", "juice",
  # K words
  "knife", "knock", "kiosk", "kinky", "kitty",
  # L words
  "light", "lunch", "layer", "leave", "lemon",
  # M words
  "media", "movie", "match", "motor", "music",
  # N words
  "never", "noise", "north", "novel", "night",
  # O words
  "ocean", "offer", "olive", "other", "opera",
  # P words
  "paint", "place", "plane", "plant", "power",
  # Q words
  "queen", "quest", "quick", "quiet", "quilt",
  # R words
  "radio", "raise", "river", "robot", "round",
  # S words
  "smart", "space", "sheep", "style", "start",
  # T words
  "table", "teach", "title", "toast", "truck",
  # U words
  "ultra", "under", "union", "urban", "usage",
  # V words
  "value", "video", "vital", "virus", "visit",
  # W words
  "watch", "water", "world", "while", "waste",
  # X words
  "xerox", "xebec",
  # Y words
  "yacht", "yield", "young", "youth", "yummy",
  # Z words
  "zebra", "zeros", "zesty",
  
  # Additional diverse words to reach 200
  "actor", "angel", "ankle", "awake", "award",
  "berry", "black", "blame", "blast", "bloom",
  "board", "break", "bring", "bunch", "cabin",
  "chair", "cheat", "chest", "chief", "child",
  "class", "clean", "clock", "coast", "comma",
  "delay", "delta", "depth", "digit", "drama",
  "eagle", "fault", "field", "flake", "flame",
  "glory", "grain", "grape", "grasp", "group",
  "hotel", "human", "humor", "ideal", "inner",
  "judge", "known", "label", "laser", "limit",
  "lunar", "march", "maple", "medal", "metal",
  "minor", "mixed", "moral", "naked", "nerve",
  "noble", "ocean", "orbit", "order", "organ",
  "panel", "pasta", "peace", "piano", "pilot",
  "pizza", "point", "pride", "proof", "pulse",
  "quake", "query", "quote", "range", "reply",
  "rider", "ridge", "rifle", "river", "roast",
  "saint", "scale", "scene", "score", "sense",
  "shape", "sharp", "shine", "shore", "skill",
  "skirt", "slice", "slide", "smile", "smoke",
  "solid", "solve", "space", "spark", "speed",
  "spicy", "spill", "sport", "squad", "stack",
  "steam", "steel", "stick", "stone", "store",
  "story", "stove", "sugar", "swamp", "sweat",
  "sweet", "swing", "sword", "table", "taste",
  "theme", "tiger", "toast", "tower", "track",
  "train", "treat", "trend", "trial", "trick",
  "trust", "truth", "twist", "unity", "upset",
  "voice", "wagon", "waist", "waltz", "whale",
  "wrist", "wrong", "yeast", "yield", "zonal"
)

# Use only 200 words in case there are more in the list
wordle_db <- common_words[1:200]
n_words <- length(wordle_db)
cat(sprintf("Our simplified Wordle database contains %d words.\n", n_words))

# Check the first letters distribution to confirm diversity
first_letters <- substr(wordle_db, 1, 1)
letter_distribution <- table(first_letters)
print("Distribution of first letters in our database:")
print(letter_distribution)
```

## Analyzing Letter Frequencies

Understanding letter frequencies will help us develop strategic guesses. Let's examine the letters used in our word database.

```{r}
# Function to calculate letter frequencies in our words
calculate_letter_frequencies <- function(words) {
  letter_counts <- table(unlist(strsplit(paste(words, collapse = ""), "")))
  letter_counts_sorted <- sort(letter_counts, decreasing = TRUE)
  return(letter_counts_sorted)
}

# Calculate and display letter frequencies
letter_freq <- calculate_letter_frequencies(wordle_db)
print("Letter frequencies in our Wordle database:")
print(letter_freq)

# Visualize letter frequencies
barplot(letter_freq, main="Letter Frequencies in Our Wordle Database", 
        xlab="Letter", ylab="Frequency", col="steelblue")
```

## Implementing Wordle Game Mechanics

Now, let's implement the core mechanics of Wordle: providing feedback for guesses and filtering the word list based on that feedback.

```{r}
# Function to simulate a Wordle guess and return feedback
# Feedback: 0 = letter not in word, 1 = letter in wrong position, 2 = letter in correct position
wordle_feedback <- function(guess, target) {
  guess_chars <- strsplit(guess, "")[[1]]
  target_chars <- strsplit(target, "")[[1]]
  
  feedback <- rep(0, 5)
  
  # First check for correct positions
  for (i in 1:5) {
    if (guess_chars[i] == target_chars[i]) {
      feedback[i] <- 2
      # Mark as used
      target_chars[i] <- "*"
      guess_chars[i] <- "#"
    }
  }
  
  # Then check for letters in wrong positions
  for (i in 1:5) {
    if (guess_chars[i] != "#") {
      pos <- match(guess_chars[i], target_chars)
      if (!is.na(pos)) {
        feedback[i] <- 1
        target_chars[pos] <- "*" # Mark as used
      }
    }
  }
  
  return(feedback)
}

# Function to filter the wordlist based on feedback
filter_words <- function(words, guess, feedback) {
  filtered <- c()
  
  for (word in words) {
    if (word == guess) next
    
    test_feedback <- wordle_feedback(guess, word)
    
    # If the feedback patterns match, keep the word
    if (all(test_feedback == feedback)) {
      filtered <- c(filtered, word)
    }
  }
  
  return(filtered)
}
```

## Initial Probability Analysis

Let's examine the initial probability of guessing correctly and how it changes after making different types of guesses.

```{r}
# Select a target word
set.seed(456) # Different seed for target selection
target_word <- sample(wordle_db, 1)

# Initial probability of guessing correctly in one try
initial_prob <- 1 / length(wordle_db)
cat(sprintf("Initial probability of guessing correctly: 1/%d = %.6f (%.6f%%)\n", 
            length(wordle_db), initial_prob, initial_prob * 100))
```

## Comparing Guessing Strategies

Let's compare two strategies:
1. Random guessing
2. Strategic guessing using words with common letters

### Strategy 1: Random Guessing

```{r}
# Make a random guess
set.seed(789) # For reproducible random guess
random_guess <- sample(wordle_db, 1)
random_feedback <- wordle_feedback(random_guess, target_word)

cat(sprintf("Random guess: '%s'\n", random_guess))
cat("Feedback (0=not in word, 1=wrong position, 2=correct position):\n")
print(random_feedback)

# Filter wordlist based on feedback
remaining_words_random <- filter_words(wordle_db, random_guess, random_feedback)
new_prob_random <- ifelse(length(remaining_words_random) > 0, 
                         1 / length(remaining_words_random), 
                         0)

cat(sprintf("After random guess, remaining possible words: %d\n", length(remaining_words_random)))
cat(sprintf("New probability of guessing correctly: 1/%d = %.6f (%.6f%%)\n", 
            length(remaining_words_random), new_prob_random, new_prob_random * 100))
cat(sprintf("Probability improvement factor: %.2fx\n", new_prob_random / initial_prob))
```

### Strategy 2: Strategic Guessing with Common Letters

```{r}
# Determine a strategic first guess based on our letter frequencies
# We'll use the most frequent letters in our database
top_letters <- names(sort(letter_freq, decreasing = TRUE)[1:5])
cat("Top 5 most frequent letters in our database:", paste(top_letters, collapse = ", "), "\n")

# Find a word that contains as many of the frequent letters as possible
# For simplicity in this exercise, we'll just check a few words manually
strategic_word_candidates <- c("earth", "stare", "raise", "tears", "rates")
letter_coverage <- numeric(length(strategic_word_candidates))

for (i in 1:length(strategic_word_candidates)) {
  word_letters <- unique(strsplit(strategic_word_candidates[i], "")[[1]])
  letter_coverage[i] <- sum(word_letters %in% top_letters)
}

strategic_guess <- strategic_word_candidates[which.max(letter_coverage)]
cat(sprintf("Strategic first guess: '%s' (covers %d of the top 5 letters)\n", 
            strategic_guess, max(letter_coverage)))

# Get feedback for the strategic guess
strategic_feedback <- wordle_feedback(strategic_guess, target_word)
cat("Feedback for strategic guess:\n")
print(strategic_feedback)

# Filter wordlist based on feedback
remaining_words_strategic <- filter_words(wordle_db, strategic_guess, strategic_feedback)
new_prob_strategic <- ifelse(length(remaining_words_strategic) > 0, 
                            1 / length(remaining_words_strategic), 
                            0)

cat(sprintf("After strategic guess, remaining possible words: %d\n", length(remaining_words_strategic)))
cat(sprintf("New probability of guessing correctly: 1/%d = %.6f (%.6f%%)\n", 
            length(remaining_words_strategic), new_prob_strategic, new_prob_strategic * 100))
cat(sprintf("Probability improvement factor: %.2fx\n", new_prob_strategic / initial_prob))
```

### Comparing the Results

```{r}
# Compare the two strategies
if (length(remaining_words_strategic) < length(remaining_words_random)) {
  cat("\nConclusion: The strategic guess with common letters was more effective at reducing the problem space.\n")
  improvement_percentage <- ((length(remaining_words_random) - length(remaining_words_strategic)) / length(remaining_words_random)) * 100
  cat(sprintf("The strategic guess reduced the possibilities by %.1f%% more than the random guess.\n", 
              improvement_percentage))
} else if (length(remaining_words_strategic) > length(remaining_words_random)) {
  cat("\nConclusion: In this particular case, the random guess was more effective (though this could be due to chance).\n")
  improvement_percentage <- ((length(remaining_words_strategic) - length(remaining_words_random)) / length(remaining_words_strategic)) * 100
  cat(sprintf("The random guess reduced the possibilities by %.1f%% more than the strategic guess.\n", 
              improvement_percentage))
} else {
  cat("\nConclusion: Both strategies resulted in the same reduction of the problem space in this example.\n")
}

cat(sprintf("\nThe target word was: '%s'\n", target_word))
```

## Simulating Many Games to See Patterns

Instead of analyzing just one game, let's simulate many games and look at the distribution of results. This lets us use `pnorm()` to ask questions about how likely different outcomes are.

```{r}
# Simulate 1000 games with a random first guess and count remaining words after guess 1
set.seed(42)
n_simulations <- 1000

remaining_after_guess <- numeric(n_simulations)

for (i in 1:n_simulations) {
  # Pick a random target
  target <- sample(wordle_db, 1)
  # Pick a random first guess (different from target)
  guess <- sample(wordle_db, 1)
  
  # Get feedback
  feedback <- wordle_feedback(guess, target)
  
  # Count remaining possible words
  remaining <- filter_words(wordle_db, guess, feedback)
  remaining_after_guess[i] <- length(remaining)
}

# Look at the distribution of remaining words after a random first guess
cat("Summary of remaining words after a random first guess:\n")
summary(remaining_after_guess)
cat(sprintf("\nMean: %.1f\n", mean(remaining_after_guess)))
cat(sprintf("Standard Deviation: %.1f\n", sd(remaining_after_guess)))
```

```{r}
# Plot the distribution
hist(remaining_after_guess, breaks = 30, col = "steelblue", 
     main = "Distribution of Remaining Words After First Guess",
     xlab = "Number of Remaining Words", ylab = "Frequency")
abline(v = mean(remaining_after_guess), col = "red", lwd = 2, lty = 2)
abline(v = mean(remaining_after_guess) + sd(remaining_after_guess), col = "blue", lwd = 2, lty = 2)
abline(v = mean(remaining_after_guess) - sd(remaining_after_guess), col = "blue", lwd = 2, lty = 2)
legend("topright", legend = c("Mean", "±1 SD"), col = c("red", "blue"), lty = 2, lwd = 2)
```

## Using pnorm() to Ask Probability Questions

Now that we have a distribution of outcomes, we can use `pnorm()` to answer practical questions. The `pnorm()` function tells us the probability of getting a value at or below a certain point in a normal distribution. It takes three key arguments: the value we're interested in, the mean, and the standard deviation.

```{r}
# Store our mean and sd for easy reference
avg_remaining <- mean(remaining_after_guess)
sd_remaining <- sd(remaining_after_guess)

cat(sprintf("Mean remaining words: %.1f\n", avg_remaining))
cat(sprintf("Standard deviation: %.1f\n", sd_remaining))
```

### Question 1: What's the probability of a "great" first guess?

Let's say a "great" first guess leaves you with 20 or fewer remaining words. How likely is that with a random guess?

```{r}
# pnorm gives us P(X <= value)
prob_great <- pnorm(20, mean = avg_remaining, sd = sd_remaining)
cat(sprintf("Probability of 20 or fewer remaining words: %.4f (%.2f%%)\n", prob_great, prob_great * 100))
```

### Question 2: What's the probability of a "bad" first guess?

A "bad" guess might leave you with 80 or more remaining words. How likely is that?

```{r}
# For P(X >= value), we use 1 - pnorm() or set lower.tail = FALSE
prob_bad <- 1 - pnorm(80, mean = avg_remaining, sd = sd_remaining)
cat(sprintf("Probability of 80 or more remaining words: %.4f (%.2f%%)\n", prob_bad, prob_bad * 100))

# Equivalently:
prob_bad_v2 <- pnorm(80, mean = avg_remaining, sd = sd_remaining, lower.tail = FALSE)
cat(sprintf("Same calculation using lower.tail = FALSE: %.4f (%.2f%%)\n", prob_bad_v2, prob_bad_v2 * 100))
```

### Question 3: What range covers the "typical" outcome?

What range of remaining words covers the middle 95% of outcomes? This is like asking: between what two values do most first guesses fall?

```{r}
# The middle 95% falls between the 2.5th and 97.5th percentiles
# We can use qnorm() (the inverse of pnorm) to find these cutoff points
lower_bound <- qnorm(0.025, mean = avg_remaining, sd = sd_remaining)
upper_bound <- qnorm(0.975, mean = avg_remaining, sd = sd_remaining)

cat(sprintf("The middle 95%% of first guesses leave between %.0f and %.0f remaining words.\n", 
            max(0, lower_bound), upper_bound))
cat(sprintf("Anything outside this range would be unusual.\n"))
```

### Question 4: How unusual is a specific outcome?

Let's say someone's first guess left only 10 words remaining. How unusual is that? We can calculate a z-score and use pnorm() to find out.

```{r}
# Calculate the z-score for 10 remaining words
value <- 10
z_score <- (value - avg_remaining) / sd_remaining
prob_at_or_below <- pnorm(value, mean = avg_remaining, sd = sd_remaining)

cat(sprintf("If a guess leaves %d remaining words:\n", value))
cat(sprintf("  Z-score: %.2f\n", z_score))
cat(sprintf("  Probability of this or fewer: %.4f (%.2f%%)\n", prob_at_or_below, prob_at_or_below * 100))
cat(sprintf("  This means only about %.1f%% of random first guesses do this well or better.\n", prob_at_or_below * 100))
```

## Comparing Strategies with pnorm()

Now let's simulate many games with the strategic approach and compare distributions.

```{r}
# Simulate 1000 games with a strategic first guess ("raise" uses common letters)
set.seed(42)
remaining_strategic <- numeric(n_simulations)

for (i in 1:n_simulations) {
  target <- sample(wordle_db, 1)
  feedback <- wordle_feedback("raise", target)
  remaining <- filter_words(wordle_db, "raise", feedback)
  remaining_strategic[i] <- length(remaining)
}

# Compare the two distributions
cat("Random guessing:\n")
cat(sprintf("  Mean: %.1f, SD: %.1f\n", mean(remaining_after_guess), sd(remaining_after_guess)))
cat("\nStrategic guessing ('raise'):\n")
cat(sprintf("  Mean: %.1f, SD: %.1f\n", mean(remaining_strategic), sd(remaining_strategic)))
```

```{r}
# Use pnorm to compare: what's the probability of leaving <= 30 words with each strategy?
threshold <- 30

prob_random_good <- pnorm(threshold, mean = mean(remaining_after_guess), sd = sd(remaining_after_guess))
prob_strategic_good <- pnorm(threshold, mean = mean(remaining_strategic), sd = sd(remaining_strategic))

cat(sprintf("Probability of %d or fewer remaining words:\n", threshold))
cat(sprintf("  Random strategy: %.2f%%\n", prob_random_good * 100))
cat(sprintf("  Strategic strategy: %.2f%%\n", prob_strategic_good * 100))
```

```{r}
# Visualize both distributions side by side
par(mfrow = c(1, 2))

hist(remaining_after_guess, breaks = 30, col = "steelblue", 
     main = "Random First Guess", xlab = "Remaining Words", 
     xlim = c(0, max(remaining_after_guess, remaining_strategic)))
abline(v = mean(remaining_after_guess), col = "red", lwd = 2, lty = 2)

hist(remaining_strategic, breaks = 30, col = "coral", 
     main = "Strategic First Guess ('raise')", xlab = "Remaining Words",
     xlim = c(0, max(remaining_after_guess, remaining_strategic)))
abline(v = mean(remaining_strategic), col = "red", lwd = 2, lty = 2)

par(mfrow = c(1, 1))
```

## Key Takeaways

This exercise has demonstrated several important concepts:

1. **Basic probability**: With 200 possible words, each guess starts as a 1-in-200 shot (0.5%). Each piece of feedback narrows the field.

2. **Distributions matter**: When we simulate many games, the number of remaining words after a guess forms a distribution with a mean and standard deviation, just like other data we've worked with.

3. **Using `pnorm()` to answer questions**: Once we know the mean and standard deviation of a distribution, `pnorm()` lets us answer questions like "how likely is this outcome?" or "what percentage of results fall below this value?" It converts any value into a probability based on the normal distribution.

4. **`pnorm()` and z-scores are connected**: Asking `pnorm(x, mean, sd)` is the same as calculating a z-score for x and then looking up that z-score's probability. The z-score tells us *how far* from typical something is; `pnorm()` tells us *how likely* that is.

5. **Comparing strategies**: By looking at the distributions from different strategies, we can use `pnorm()` to quantify how much better one approach is than another — not just in one game, but across many possible outcomes.
